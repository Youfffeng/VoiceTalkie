//
//  WhisperManager.swift
//  VoiceTalkie
//
//  Created by Qoder on 11/18/25.
//

import Foundation
import AVFoundation
import WhisperKit
import Combine

/// Manager for WhisperKit speech recognition
@MainActor
class WhisperManager: ObservableObject {
    static let shared = WhisperManager()
    
    // MARK: - Published Properties
    
    @Published var isInitialized = false
    @Published var isTranscribing = false
    @Published var currentModel: WhisperModel = .small
    @Published var downloadProgress: Double = 0.0
    @Published var isDownloading = false
    @Published var transcriptionText = ""
    @Published var error: WhisperError?
    
    // MARK: - Private Properties
    
    private var whisperKit: WhisperKit?
    private var audioEngine: AVAudioEngine?
    private var inputNode: AVAudioInputNode?
    
    /// Êú¨Âú∞Ê®°ÂûãÂ≠òÂÇ®Ë∑ØÂæÑÔºàApplication SupportÔºâ
    private lazy var localModelsPath: URL = {
        let appSupport = FileManager.default.urls(for: .applicationSupportDirectory, in: .userDomainMask).first!
        let modelsDir = appSupport.appendingPathComponent("whisperkit-models")
        
        // Á°Æ‰øùÁõÆÂΩïÂ≠òÂú®
        try? FileManager.default.createDirectory(at: modelsDir, withIntermediateDirectories: true)
        
        return modelsDir
    }()
    
    /// Bundle‰∏≠È¢ÑÊâìÂåÖÁöÑÊ®°ÂûãË∑ØÂæÑ
    private var bundledModelPath: URL? {
        // Êü•Êâæ Bundle ‰∏≠ÁöÑÊ®°ÂûãÊñá‰ª∂Â§π
        // Ê®°ÂûãÊñá‰ª∂Â§πÂëΩÂêçÊ†ºÂºèÔºöopenai_whisper-{model_name}
        return Bundle.main.url(forResource: "openai_whisper-\(currentModel.rawValue)", withExtension: nil)
    }
    
    // MARK: - Initialization
    
    private init() {
        // Load saved model preference
        if let savedModel = UserDefaults.standard.string(forKey: "selectedWhisperModel"),
           let model = WhisperModel(rawValue: savedModel) {
            currentModel = model
        }
    }
    
    // MARK: - Model Management
    
    /// Ê£ÄÊµãÂπ∂ÂáÜÂ§áÊú¨Âú∞Ê®°Âûã
    private func prepareLocalModel(modelName: String) -> URL? {
        // Ê∑ªÂä†Ëá™Âä®ÈáäÊîæÊ±†ÔºåÈò≤Ê≠¢ÂÜÖÂ≠òÈóÆÈ¢ò
        return autoreleasepool {
            let modelFolderName = "openai_whisper-\(modelName)"
            let localModelPath = localModelsPath.appendingPathComponent(modelFolderName)
            
            print("\nüîç [WhisperManager] ========== ÂºÄÂßãÊ£ÄÊµãÊ®°Âûã ==========")
            print("üìù [WhisperManager] ÁõÆÊ†áÊ®°Âûã: \(modelName)")
        
        // 1. Ê£ÄÊü• Application Support ‰∏≠ÊòØÂê¶Â∑≤ÊúâÊ®°Âûã
        if FileManager.default.fileExists(atPath: localModelPath.path) {
            print("‚úÖ [WhisperManager] ÊâæÂà∞Êú¨Âú∞Ê®°Âûã: \(localModelPath.path)")
            print("üîç [WhisperManager] ========== Ê®°ÂûãÊ£ÄÊµãÂÆåÊàê ==========\n")
            return localModelPath
        }
        
        // 2. Ê£ÄÊü• Bundle ‰∏≠ÊòØÂê¶ÊúâÈ¢ÑÊâìÂåÖÊ®°ÂûãÔºàÂ∏¶Êñá‰ª∂Â§πÁªìÊûÑÔºâ
        print("üîé [WhisperManager] Application Support‰∏≠‰∏çÂ≠òÂú®ÔºåÊ£ÄÊü•Bundle...")
        
        if let bundledPath = Bundle.main.url(forResource: modelFolderName, withExtension: nil) {
            print("üì¶ [WhisperManager] ‚úÖ ÊâæÂà∞Bundle‰∏≠ÁöÑÊ®°ÂûãÔºàÊñá‰ª∂Â§πÁªìÊûÑÔºâ: \(bundledPath.path)")
            
            // Â∞ùËØïÂ§çÂà∂Âà∞ Application Support
            print("üìã [WhisperManager] Â∞ùËØïÂ§çÂà∂Ê®°ÂûãÂà∞Application Support...")
            do {
                try FileManager.default.copyItem(at: bundledPath, to: localModelPath)
                print("‚úÖ [WhisperManager] Â∑≤Â§çÂà∂Ê®°ÂûãÂà∞Êú¨Âú∞: \(localModelPath.path)")
                print("üîç [WhisperManager] ========== Ê®°ÂûãÊ£ÄÊµãÂÆåÊàê ==========\n")
                return localModelPath
            } catch {
                print("‚ö†Ô∏è [WhisperManager] Â§çÂà∂Ê®°ÂûãÂ§±Ë¥•: \(error.localizedDescription)")
                print("   Â∞ÜÁõ¥Êé•‰ΩøÁî®BundleË∑ØÂæÑ")
                print("üîç [WhisperManager] ========== Ê®°ÂûãÊ£ÄÊµãÂÆåÊàê ==========\n")
                // Â¶ÇÊûúÂ§çÂà∂Â§±Ë¥•ÔºåÁõ¥Êé•‰ΩøÁî® Bundle Ë∑ØÂæÑ
                return bundledPath
            }
        }
        
        // 3. Ê£ÄÊü• Bundle Resources Ê†πÁõÆÂΩïÔºàÊñá‰ª∂Ë¢´Â±ïÂºÄÁöÑÊÉÖÂÜµÔºâ
        print("üîé [WhisperManager] Êú™ÊâæÂà∞Êñá‰ª∂Â§πÁªìÊûÑÔºåÊ£ÄÊü•BundleÊ†πÁõÆÂΩï‰∏≠ÁöÑÊ®°ÂûãÊñá‰ª∂...")
        
        if let resourceURL = Bundle.main.resourceURL {
            // Ê£ÄÊü•ÂÖ≥ÈîÆÁöÑÊ®°ÂûãÊñá‰ª∂ÊòØÂê¶Â≠òÂú®‰∫éBundleÊ†πÁõÆÂΩï
            let audioEncoderPath = resourceURL.appendingPathComponent("AudioEncoder.mlmodelc")
            let textDecoderPath = resourceURL.appendingPathComponent("TextDecoder.mlmodelc")
            let melSpectrogramPath = resourceURL.appendingPathComponent("MelSpectrogram.mlmodelc")
            let configPath = resourceURL.appendingPathComponent("config.json")
            
            let hasAllFiles = FileManager.default.fileExists(atPath: audioEncoderPath.path) &&
                             FileManager.default.fileExists(atPath: textDecoderPath.path) &&
                             FileManager.default.fileExists(atPath: melSpectrogramPath.path) &&
                             FileManager.default.fileExists(atPath: configPath.path)
            
            if hasAllFiles {
                print("üì¶ [WhisperManager] ‚úÖ ÊâæÂà∞BundleÊ†πÁõÆÂΩï‰∏≠ÁöÑÊ®°ÂûãÊñá‰ª∂")
                print("üìã [WhisperManager] Ê®°ÂûãÊñá‰ª∂‰ΩçÁΩÆ: \(resourceURL.path)")
                
                // ÂàõÂª∫ÁõÆÊ†áÊñá‰ª∂Â§π
                do {
                    try FileManager.default.createDirectory(at: localModelPath, withIntermediateDirectories: true)
                    
                    // Â§çÂà∂ÊâÄÊúâÊ®°ÂûãÁõ∏ÂÖ≥Êñá‰ª∂Âà∞ÁõÆÊ†áÊñá‰ª∂Â§π
                    let filesToCopy = [
                        "AudioEncoder.mlmodelc",
                        "AudioEncoder.mlcomputeplan.json",
                        "TextDecoder.mlmodelc",
                        "TextDecoder.mlcomputeplan.json",
                        "MelSpectrogram.mlmodelc",
                        "MelSpectrogram.mlcomputeplan.json",
                        "config.json",
                        "generation_config.json",
                        "tokenizer.json",
                        "tokenizer_config.json",
                        "vocab.json",
                        "merges.txt"
                    ]
                    
                    for fileName in filesToCopy {
                        let sourcePath = resourceURL.appendingPathComponent(fileName)
                        let destPath = localModelPath.appendingPathComponent(fileName)
                        
                        if FileManager.default.fileExists(atPath: sourcePath.path) {
                            // Â¶ÇÊûúÁõÆÊ†áÂ∑≤Â≠òÂú®ÔºåÂÖàÂà†Èô§
                            if FileManager.default.fileExists(atPath: destPath.path) {
                                try? FileManager.default.removeItem(at: destPath)
                            }
                            try FileManager.default.copyItem(at: sourcePath, to: destPath)
                        }
                    }
                    
                    print("‚úÖ [WhisperManager] Â∑≤ÈáçÁªÑÊ®°ÂûãÊñá‰ª∂Âà∞Êú¨Âú∞: \(localModelPath.path)")
                    print("üîç [WhisperManager] ========== Ê®°ÂûãÊ£ÄÊµãÂÆåÊàê ==========\n")
                    return localModelPath
                    
                } catch {
                    print("‚ö†Ô∏è [WhisperManager] ÈáçÁªÑÊ®°ÂûãÊñá‰ª∂Â§±Ë¥•: \(error.localizedDescription)")
                    print("   Â∞ÜÁõ¥Êé•‰ΩøÁî®BundleÊ†πÁõÆÂΩï")
                    print("üîç [WhisperManager] ========== Ê®°ÂûãÊ£ÄÊµãÂÆåÊàê ==========\n")
                    // Áõ¥Êé•ËøîÂõûBundleÁöÑresourceURLÔºåËÆ©WhisperKit‰ªéÈÇ£ÈáåÂä†ËΩΩ
                    return resourceURL
                }
            }
        }
        
        print("‚ùå [WhisperManager] Êú™ÊâæÂà∞Êú¨Âú∞ÊàñBundle‰∏≠ÁöÑÊ®°Âûã: \(modelFolderName)")
        print("üîç [WhisperManager] ========== Ê®°ÂûãÊ£ÄÊµãÂÆåÊàê(Êú™ÊâæÂà∞) ==========\n")
        return nil
        } // autoreleasepool
    }
    
    /// Initialize WhisperKit with specified model
    func initialize(model: WhisperModel? = nil) async throws {
        let modelToUse = model ?? currentModel
        
        print("\nüöÄ [WhisperManager] ========== ÂºÄÂßãÂàùÂßãÂåñWhisperKit ==========")
        print("üìù [WhisperManager] ËØ∑Ê±ÇÁöÑÊ®°Âûã: \(modelToUse.rawValue)")
        print("üìù [WhisperManager] ÂΩìÂâçÊ®°Âûã: \(currentModel.rawValue)")
        print("üìù [WhisperManager] ÂàùÂßãÂåñÁä∂ÊÄÅ: \(isInitialized)")
        
        guard !isInitialized else {
            print("‚ö†Ô∏è [WhisperManager] WhisperKitÂ∑≤ÁªèÂàùÂßãÂåñÔºåË∑≥Ëøá")
            print("üöÄ [WhisperManager] ========== ÂàùÂßãÂåñÁªìÊùü ==========\n")
            return
        }
        
        isDownloading = true
        downloadProgress = 0.0
        
        do {
            // ÂÖàÂ∞ùËØï‰ΩøÁî®Êú¨Âú∞Ê®°Âûã
            if let localModelPath = prepareLocalModel(modelName: modelToUse.rawValue) {
                print("\nüìÅ [WhisperManager] ÂáÜÂ§á‰ΩøÁî®Êú¨Âú∞Ê®°Âûã")
                print("üìÇ [WhisperManager] Ê®°ÂûãÊñá‰ª∂Â§πË∑ØÂæÑ: \(localModelPath.path)")
                
                let config = WhisperKitConfig(
                    modelFolder: localModelPath.path,
                    verbose: true,
                    logLevel: .debug
                )
                
                print("‚öôÔ∏è [WhisperManager] WhisperKitConfig:")
                print("   - modelFolder: \(config.modelFolder ?? "nil")")
                
                // È™åËØÅÊ®°ÂûãÊñá‰ª∂ÂÆåÊï¥ÊÄß
                print("\nüîç [WhisperManager] È™åËØÅÊ®°ÂûãÊñá‰ª∂...")
                let requiredFiles = [
                    "AudioEncoder.mlmodelc/model.mil",
                    "AudioEncoder.mlmodelc/coremldata.bin",
                    "MelSpectrogram.mlmodelc/model.mil",
                    "MelSpectrogram.mlmodelc/coremldata.bin",
                    "TextDecoder.mlmodelc/model.mil",
                    "TextDecoder.mlmodelc/coremldata.bin",
                    "config.json",
                    "tokenizer.json"
                ]
                
                for file in requiredFiles {
                    let filePath = localModelPath.appendingPathComponent(file)
                    let exists = FileManager.default.fileExists(atPath: filePath.path)
                    let size = (try? FileManager.default.attributesOfItem(atPath: filePath.path)[.size] as? UInt64) ?? 0
                    print("   \(exists ? "‚úÖ" : "‚ùå") \(file): \(ByteCountFormatter.string(fromByteCount: Int64(size), countStyle: .file))")
                }
                
                print("\nüîÑ [WhisperManager] ÂºÄÂßãÂàõÂª∫WhisperKitÂÆû‰æã...")
                print("‚è∞ [WhisperManager] ËøôÂèØËÉΩÈúÄË¶Å 10-30 ÁßíÔºåËØ∑ËÄêÂøÉÁ≠âÂæÖ...")
                
                let startTime = Date()
                whisperKit = try await WhisperKit(config)
                let duration = Date().timeIntervalSince(startTime)
                
                print("‚è±Ô∏è [WhisperManager] WhisperKit ÂàùÂßãÂåñËÄóÊó∂: \(String(format: "%.2f", duration)) Áßí")
                
                isInitialized = true
                currentModel = modelToUse
                isDownloading = false
                
                UserDefaults.standard.set(modelToUse.rawValue, forKey: "selectedWhisperModel")
                print("‚úÖ [WhisperManager] ‰ΩøÁî®Êú¨Âú∞Ê®°ÂûãÂàùÂßãÂåñÊàêÂäü: \(modelToUse.rawValue)")
                print("üöÄ [WhisperManager] ========== ÂàùÂßãÂåñÊàêÂäü ==========\n")
                return
            }
            
            // Â¶ÇÊûúÊ≤°ÊúâÊú¨Âú∞Ê®°ÂûãÔºåÂàô‰ªéÁΩëÁªú‰∏ãËΩΩ
            print("\nüåê [WhisperManager] Êú¨Âú∞Ê®°Âûã‰∏çÂ≠òÂú®ÔºåÂáÜÂ§á‰ªéÁΩëÁªú‰∏ãËΩΩ")
            print("üìÇ [WhisperManager] ‰∏ãËΩΩÁõÆÊ†áË∑ØÂæÑ: \(localModelsPath.path)")
            
            let config = WhisperKitConfig(
                model: modelToUse.rawValue,
                modelFolder: localModelsPath.path,
                verbose: false,
                logLevel: .none
            )
            
            print("‚öôÔ∏è [WhisperManager] WhisperKitConfig:")
            print("   - model: \(config.model ?? "nil")")
            print("   - modelFolder: \(config.modelFolder ?? "nil")")
            
            print("üîÑ [WhisperManager] ÂºÄÂßãÂàõÂª∫WhisperKitÂÆû‰æã(Â∞Ü‰ªéÁΩëÁªú‰∏ãËΩΩ)...")
            whisperKit = try await WhisperKit(config)
            
            isInitialized = true
            currentModel = modelToUse
            isDownloading = false
            
            UserDefaults.standard.set(modelToUse.rawValue, forKey: "selectedWhisperModel")
            print("‚úÖ [WhisperManager] ÁΩëÁªú‰∏ãËΩΩÊ®°ÂûãÂàùÂßãÂåñÊàêÂäü: \(modelToUse.rawValue)")
            print("üöÄ [WhisperManager] ========== ÂàùÂßãÂåñÊàêÂäü ==========\n")
            
        } catch {
            isDownloading = false
            self.error = .initializationFailed(error.localizedDescription)
            print("\n‚ùå [WhisperManager] Ê®°ÂûãÂàùÂßãÂåñÂ§±Ë¥•")
            print("   ÈîôËØØÁ±ªÂûã: \(type(of: error))")
            print("   ÈîôËØØÊèèËø∞: \(error.localizedDescription)")
            print("   ËØ¶ÁªÜ‰ø°ÊÅØ: \(error)")
            print("üöÄ [WhisperManager] ========== ÂàùÂßãÂåñÂ§±Ë¥• ==========\n")
            throw error
        }
    }
    
    /// Switch to a different model
    func switchModel(to model: WhisperModel) async throws {
        guard model != currentModel else { return }
        
        // Reset current instance
        whisperKit = nil
        isInitialized = false
        
        // Initialize with new model
        try await initialize(model: model)
    }
    
    /// Ê£ÄÊü•Ê®°ÂûãÊòØÂê¶Êú¨Âú∞ÂèØÁî®
    func isModelAvailableLocally(_ model: WhisperModel) -> Bool {
        let modelFolderName = "openai_whisper-\(model.rawValue)"
        
        // Ê£ÄÊü• Application Support
        let localPath = localModelsPath.appendingPathComponent(modelFolderName)
        if FileManager.default.fileExists(atPath: localPath.path) {
            return true
        }
        
        // Ê£ÄÊü• Bundle
        if Bundle.main.url(forResource: modelFolderName, withExtension: nil) != nil {
            return true
        }
        
        return false
    }
    
    /// Ëé∑ÂèñÊ®°ÂûãÊñá‰ª∂Â§ßÂ∞èÔºàÂ¶ÇÊûúÂ≠òÂú®Ôºâ
    func getModelSize(_ model: WhisperModel) -> String? {
        let modelFolderName = "openai_whisper-\(model.rawValue)"
        
        // Ê£ÄÊü• Application Support
        let localPath = localModelsPath.appendingPathComponent(modelFolderName)
        if FileManager.default.fileExists(atPath: localPath.path),
           let size = try? FileManager.default.attributesOfItem(atPath: localPath.path)[.size] as? UInt64 {
            return ByteCountFormatter.string(fromByteCount: Int64(size), countStyle: .file)
        }
        
        // Ê£ÄÊü• Bundle
        if let bundlePath = Bundle.main.url(forResource: modelFolderName, withExtension: nil),
           let size = try? FileManager.default.attributesOfItem(atPath: bundlePath.path)[.size] as? UInt64 {
            return ByteCountFormatter.string(fromByteCount: Int64(size), countStyle: .file)
        }
        
        return nil
    }
    
    // MARK: - Transcription
    
    /// Transcribe audio from a file URL
    func transcribe(audioURL: URL) async throws -> TranscriptionResult {
        print("ü§ñ [WhisperManager] transcribe() called")
        print("üìÅ [WhisperManager] Audio file: \(audioURL.path)")
        
        guard isInitialized else {
            print("‚ùå [WhisperManager] WhisperKit not initialized")
            throw WhisperError.notInitialized
        }
        print("‚úÖ [WhisperManager] WhisperKit is initialized")
        
        guard !isTranscribing else {
            print("‚ö†Ô∏è [WhisperManager] Already transcribing")
            throw WhisperError.alreadyTranscribing
        }
        
        isTranscribing = true
        transcriptionText = ""
        print("üîÑ [WhisperManager] Starting transcription with model: \(currentModel.rawValue)")
        
        do {
            let startTime = Date()
            
            // Ëé∑ÂèñÁî®Êà∑Ëá™ÂÆö‰πâÁöÑ prompt
            let settings = AppSettings.shared
            let promptText = settings.whisperPrompt.trimmingCharacters(in: .whitespacesAndNewlines)
            
            var promptTokens: [Int]? = nil
            if !promptText.isEmpty, let tokenizer = whisperKit?.tokenizer {
                // Â∞Ü prompt ÊñáÊú¨ËΩ¨Êç¢‰∏∫ tokens
                promptTokens = tokenizer.encode(text: promptText).filter { $0 < tokenizer.specialTokens.specialTokenBegin }
                print("üìù [WhisperManager] Using prompt: '\(promptText)'")
                print("üî¢ [WhisperManager] Prompt tokens count: \(promptTokens?.count ?? 0)")
            }
            
            // üåè Âº∫Âà∂‰ΩøÁî®‰∏≠ÊñáËØÜÂà´
            print("üåè [WhisperManager] Using language: Chinese (zh)")
            let result = try await whisperKit?.transcribe(
                audioPath: audioURL.path,
                decodeOptions: DecodingOptions(
                    task: .transcribe,
                    language: "zh",  // Âº∫Âà∂‰∏≠Êñá
                    temperature: 0.0,
                    temperatureFallbackCount: 5,
                    sampleLength: 224,
                    topK: 5,
                    usePrefillPrompt: true,
                    usePrefillCache: true,
                    promptTokens: promptTokens  // ‰ΩøÁî®Ëá™ÂÆö‰πâ prompt
                )
            ) ?? []
            
            let duration = Date().timeIntervalSince(startTime)
            
            print("‚è±Ô∏è [WhisperManager] Transcription took \(String(format: "%.2f", duration)) seconds")
            print("üìä [WhisperManager] Result count: \(result.count)")
            
            let text = result.first?.text ?? ""
            print("üìù [WhisperManager] Raw transcription result: '\(text)'")
            print("üìè [WhisperManager] Text length: \(text.count) characters")
            
            let transcriptionResult = TranscriptionResult(
                text: text,
                confidence: nil,
                isFinal: true,
                timestamp: Date(),
                language: nil,
                duration: duration
            )
            
            transcriptionText = text
            isTranscribing = false
            
            print("‚úÖ [WhisperManager] Transcription completed successfully")
            return transcriptionResult
            
        } catch {
            print("‚ùå [WhisperManager] Transcription error: \(error)")
            print("‚ùå [WhisperManager] Error description: \(error.localizedDescription)")
            isTranscribing = false
            self.error = .transcriptionFailed(error.localizedDescription)
            throw error
        }
    }
    
    /// Transcribe audio from PCM buffer (for real-time streaming)
    func transcribe(audioBuffer: AVAudioPCMBuffer) async throws -> TranscriptionResult {
        guard isInitialized else {
            throw WhisperError.notInitialized
        }
        
        // TODO: Implement streaming transcription with WhisperKit
        // This will be used for real-time transcription
        
        throw WhisperError.notImplemented
    }
    
    /// Start real-time transcription from microphone
    func startRealtimeTranscription() async throws {
        guard isInitialized else {
            throw WhisperError.notInitialized
        }
        
        // TODO: Implement real-time audio capture and transcription
        // This will involve:
        // 1. Setting up AVAudioEngine
        // 2. Capturing audio buffers
        // 3. Feeding them to WhisperKit incrementally
        // 4. Publishing interim and final results
        
        isTranscribing = true
    }
    
    /// Stop real-time transcription
    func stopRealtimeTranscription() {
        audioEngine?.stop()
        inputNode?.removeTap(onBus: 0)
        isTranscribing = false
    }
    
    // MARK: - Cleanup
    
    func cleanup() {
        stopRealtimeTranscription()
        whisperKit = nil
        isInitialized = false
    }
}

// MARK: - Whisper Error Types

enum WhisperError: LocalizedError {
    case notInitialized
    case initializationFailed(String)
    case alreadyTranscribing
    case transcriptionFailed(String)
    case modelNotFound(String)
    case notImplemented
    
    var errorDescription: String? {
        switch self {
        case .notInitialized:
            return NSLocalizedString("error.whisper.not_initialized", comment: "WhisperKit is not initialized")
        case .initializationFailed(let message):
            return NSLocalizedString("error.whisper.init_failed", comment: "Failed to initialize: \(message)")
        case .alreadyTranscribing:
            return NSLocalizedString("error.whisper.already_transcribing", comment: "Already transcribing")
        case .transcriptionFailed(let message):
            return NSLocalizedString("error.whisper.transcription_failed", comment: "Transcription failed: \(message)")
        case .modelNotFound(let model):
            return NSLocalizedString("error.whisper.model_not_found", comment: "Model not found: \(model)")
        case .notImplemented:
            return NSLocalizedString("error.whisper.not_implemented", comment: "Feature not implemented yet")
        }
    }
}
